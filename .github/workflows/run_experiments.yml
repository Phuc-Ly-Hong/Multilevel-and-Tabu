name: Compare Multilevel Tabu vs Tabu Search

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:

permissions:
  contents: read

jobs:
  compile:
    name: Compile Both Algorithms
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y g++ bc
    
    - name: Compile both executables
      run: |
        g++ -O2 -std=c++17 -o multilevel_tabu src/Multilevel_Tabu.cpp
        g++ -O2 -std=c++17 -o tabu src/Tabu.cpp
        chmod +x multilevel_tabu tabu
        ls -lh multilevel_tabu tabu
    
    - name: Upload executables
      uses: actions/upload-artifact@v4
      with:
        name: executables
        path: |
          multilevel_tabu
          tabu
        retention-days: 1

  run-small:
    name: Small ${{ matrix.instance }}
    needs: compile
    runs-on: ubuntu-latest
    timeout-minutes: 100
    
    strategy:
      fail-fast: false
      max-parallel: 12
      matrix:
        instance: [
          "6.5.1", "6.5.2", "6.5.3", "6.5.4",
          "6.10.1", "6.10.2", "6.10.3", "6.10.4",
          "6.20.1", "6.20.2", "6.20.3", "6.20.4",
          "10.5.1", "10.5.2", "10.5.3", "10.5.4",
          "10.10.1", "10.10.2", "10.10.3", "10.10.4",
          "10.20.1", "10.20.2", "10.20.3", "10.20.4",
          "12.5.1", "12.5.2", "12.5.3", "12.5.4",
          "12.10.1", "12.10.2", "12.10.3", "12.10.4",
          "12.20.1", "12.20.2", "12.20.3", "12.20.4",
          "20.5.1", "20.5.2", "20.5.3", "20.5.4",
          "20.10.1", "20.10.2", "20.10.3", "20.10.4",
          "20.20.1", "20.20.2", "20.20.3", "20.20.4"
        ]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Download executables
      uses: actions/download-artifact@v4
      with:
        name: executables
    
    - name: Run both algorithms 5 times each
      run: |
        chmod +x multilevel_tabu tabu
        
        echo "üîÑ Running instance ${{ matrix.instance }} - 5 runs per algorithm"
        
        # Run Multilevel Tabu 5 times
        for run in {1..5}; do
          echo "========== MULTILEVEL TABU - RUN $run/5 =========="
          START_TIME=$(date +%s.%N)
          timeout 8m ./multilevel_tabu instances/${{ matrix.instance }}.txt > multilevel_run${run}.txt 2>&1 || true
          END_TIME=$(date +%s.%N)
          RUNTIME=$(echo "$END_TIME - $START_TIME" | bc)
          echo "$RUNTIME" > multilevel_runtime${run}.txt
          echo "‚è±Ô∏è  Multilevel run $run: ${RUNTIME}s"
        done
        
        # Run Tabu 5 times
        for run in {1..5}; do
          echo "========== TABU SEARCH - RUN $run/5 =========="
          START_TIME=$(date +%s.%N)
          timeout 8m ./tabu instances/${{ matrix.instance }}.txt > tabu_run${run}.txt 2>&1 || true
          END_TIME=$(date +%s.%N)
          RUNTIME=$(echo "$END_TIME - $START_TIME" | bc)
          echo "$RUNTIME" > tabu_runtime${run}.txt
          echo "‚è±Ô∏è  Tabu run $run: ${RUNTIME}s"
        done
        
        echo "‚úÖ All 10 runs completed!"
    
    - name: Parse results and create comparison JSON
      run: |
        python3 <<'EOF'
        import re, json, os
        instance = "${{ matrix.instance }}"
        
        def find_metric(pattern, content):
            m = re.search(pattern, content)
            return float(m.group(1)) if m else 0.0
        
        def parse_output(output_file, runtime_file):
            try:
                with open(output_file, "r", encoding="utf-8", errors="ignore") as f:
                    content = f.read()
                runtime = 0.0
                if os.path.exists(runtime_file):
                    with open(runtime_file, "r") as f:
                        runtime = float(f.read().strip())
                
                makespan = find_metric(r'Makespan:\s*([0-9.+\-eE]+)', content)
                drone_viol = find_metric(r'Drone violation:\s*([0-9.+\-eE]+)', content)
                waiting_viol = find_metric(r'Waiting violation:\s*([0-9.+\-eE]+)', content)
                fitness = find_metric(r'Fitness:\s*([0-9.+\-eE]+)', content)
                
                routes = []
                idx = content.rfind("Route details:")
                if idx != -1:
                    for line in content[idx:].splitlines():
                        if line.startswith("Vehicle "):
                            m = re.match(r'Vehicle\s+(\d+):\s*(.+)', line)
                            if m:
                                routes.append(f"V{m.group(1)}:{m.group(2).strip()}")
                
                feasible = "YES" if (abs(drone_viol) < 1e-6 and abs(waiting_viol) < 1e-6) else "NO"
                
                return {
                    "runtime": round(runtime, 3),
                    "makespan": round(makespan, 4),
                    "drone_violation": round(drone_viol, 4),
                    "waiting_violation": round(waiting_viol, 4),
                    "fitness": round(fitness, 4),
                    "feasible": feasible,
                    "routes": " | ".join(routes)
                }
            except Exception as e:
                return {
                    "runtime": 0, "makespan": 0, "drone_violation": 0,
                    "waiting_violation": 0, "fitness": float('inf'),
                    "feasible": "ERROR", "routes": f"Error: {e}"
                }
        
        # Parse Multilevel Tabu runs
        multilevel_runs = []
        for run in range(1, 6):
            result = parse_output(f"multilevel_run{run}.txt", f"multilevel_runtime{run}.txt")
            result["run"] = run
            result["algorithm"] = "Multilevel_Tabu"
            multilevel_runs.append(result)
            print(f"Multilevel Run {run}: Fitness={result['fitness']}, Feasible={result['feasible']}")
        
        # Parse Tabu runs
        tabu_runs = []
        for run in range(1, 6):
            result = parse_output(f"tabu_run{run}.txt", f"tabu_runtime{run}.txt")
            result["run"] = run
            result["algorithm"] = "Tabu"
            tabu_runs.append(result)
            print(f"Tabu Run {run}: Fitness={result['fitness']}, Feasible={result['feasible']}")
        
        # Save to JSON
        with open("comparison_results.json", "w", encoding="utf-8") as f:
            json.dump({
                "instance": instance,
                "multilevel_runs": multilevel_runs,
                "tabu_runs": tabu_runs
            }, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ Comparison results saved for {instance}")
        EOF
    
    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: result-${{ matrix.instance }}
        path: |
          comparison_results.json
          multilevel_run*.txt
          tabu_run*.txt
        retention-days: 30

  run-medium:
    name: Medium ${{ matrix.instance }}
    needs: compile
    runs-on: ubuntu-latest
    timeout-minutes: 200
    
    strategy:
      fail-fast: false
      max-parallel: 8
      matrix:
        instance: [
          "50.10.1", "50.10.2", "50.10.3", "50.10.4",
          "50.20.1", "50.20.2", "50.20.3", "50.20.4",
          "50.30.1", "50.30.2", "50.30.3", "50.30.4",
          "50.40.1", "50.40.2", "50.40.3", "50.40.4"
        ]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Download executables
      uses: actions/download-artifact@v4
      with:
        name: executables
    
    - name: Run both algorithms 5 times each
      run: |
        chmod +x multilevel_tabu tabu
        
        for run in {1..5}; do
          START_TIME=$(date +%s.%N)
          timeout 18m ./multilevel_tabu instances/${{ matrix.instance }}.txt > multilevel_run${run}.txt 2>&1 || true
          END_TIME=$(date +%s.%N)
          echo "$(echo "$END_TIME - $START_TIME" | bc)" > multilevel_runtime${run}.txt
        done
        
        for run in {1..5}; do
          START_TIME=$(date +%s.%N)
          timeout 18m ./tabu instances/${{ matrix.instance }}.txt > tabu_run${run}.txt 2>&1 || true
          END_TIME=$(date +%s.%N)
          echo "$(echo "$END_TIME - $START_TIME" | bc)" > tabu_runtime${run}.txt
        done
    
    - name: Parse results
      run: |
        python3 <<'EOF'
        import re, json, os
        instance = "${{ matrix.instance }}"
        
        def find_metric(pattern, content):
            m = re.search(pattern, content)
            return float(m.group(1)) if m else 0.0
        
        def parse_output(output_file, runtime_file):
            try:
                with open(output_file, "r", encoding="utf-8", errors="ignore") as f:
                    content = f.read()
                runtime = 0.0
                if os.path.exists(runtime_file):
                    with open(runtime_file, "r") as f:
                        runtime = float(f.read().strip())
                makespan = find_metric(r'Makespan:\s*([0-9.+\-eE]+)', content)
                drone_viol = find_metric(r'Drone violation:\s*([0-9.+\-eE]+)', content)
                waiting_viol = find_metric(r'Waiting violation:\s*([0-9.+\-eE]+)', content)
                fitness = find_metric(r'Fitness:\s*([0-9.+\-eE]+)', content)
                routes = []
                idx = content.rfind("Route details:")
                if idx != -1:
                    for line in content[idx:].splitlines():
                        if line.startswith("Vehicle "):
                            m = re.match(r'Vehicle\s+(\d+):\s*(.+)', line)
                            if m:
                                routes.append(f"V{m.group(1)}:{m.group(2).strip()}")
                feasible = "YES" if (abs(drone_viol) < 1e-6 and abs(waiting_viol) < 1e-6) else "NO"
                return {
                    "runtime": round(runtime, 3), "makespan": round(makespan, 4),
                    "drone_violation": round(drone_viol, 4), "waiting_violation": round(waiting_viol, 4),
                    "fitness": round(fitness, 4), "feasible": feasible, "routes": " | ".join(routes)
                }
            except:
                return {"runtime": 0, "makespan": 0, "drone_violation": 0, "waiting_violation": 0,
                        "fitness": float('inf'), "feasible": "ERROR", "routes": ""}
        
        multilevel_runs = []
        for run in range(1, 6):
            result = parse_output(f"multilevel_run{run}.txt", f"multilevel_runtime{run}.txt")
            result["run"] = run
            result["algorithm"] = "Multilevel_Tabu"
            multilevel_runs.append(result)
        
        tabu_runs = []
        for run in range(1, 6):
            result = parse_output(f"tabu_run{run}.txt", f"tabu_runtime{run}.txt")
            result["run"] = run
            result["algorithm"] = "Tabu"
            tabu_runs.append(result)
        
        with open("comparison_results.json", "w", encoding="utf-8") as f:
            json.dump({"instance": instance, "multilevel_runs": multilevel_runs, "tabu_runs": tabu_runs}, f, indent=2)
        EOF
    
    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: result-${{ matrix.instance }}
        path: comparison_results.json
        retention-days: 30

  run-large:
    name: Large ${{ matrix.instance }}
    needs: compile
    runs-on: ubuntu-latest
    timeout-minutes: 400
    
    strategy:
      fail-fast: false
      max-parallel: 6
      matrix:
        instance: [
          "100.10.1", "100.10.2", "100.10.3", "100.10.4",
          "100.20.1", "100.20.2", "100.20.3", "100.20.4",
          "100.30.1", "100.30.2", "100.30.3", "100.30.4",
          "100.40.1", "100.40.2", "100.40.3", "100.40.4"
        ]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Download executables
      uses: actions/download-artifact@v4
      with:
        name: executables
    
    - name: Run both algorithms 5 times each
      run: |
        chmod +x multilevel_tabu tabu
        
        for run in {1..5}; do
          START_TIME=$(date +%s.%N)
          timeout 35m ./multilevel_tabu instances/${{ matrix.instance }}.txt > multilevel_run${run}.txt 2>&1 || true
          END_TIME=$(date +%s.%N)
          echo "$(echo "$END_TIME - $START_TIME" | bc)" > multilevel_runtime${run}.txt
        done
        
        for run in {1..5}; do
          START_TIME=$(date +%s.%N)
          timeout 35m ./tabu instances/${{ matrix.instance }}.txt > tabu_run${run}.txt 2>&1 || true
          END_TIME=$(date +%s.%N)
          echo "$(echo "$END_TIME - $START_TIME" | bc)" > tabu_runtime${run}.txt
        done
    
    - name: Parse results
      run: |
        python3 <<'EOF'
        import re, json, os
        instance = "${{ matrix.instance }}"
        
        def find_metric(pattern, content):
            m = re.search(pattern, content)
            return float(m.group(1)) if m else 0.0
        
        def parse_output(output_file, runtime_file):
            try:
                with open(output_file, "r", encoding="utf-8", errors="ignore") as f:
                    content = f.read()
                runtime = 0.0
                if os.path.exists(runtime_file):
                    with open(runtime_file, "r") as f:
                        runtime = float(f.read().strip())
                makespan = find_metric(r'Makespan:\s*([0-9.+\-eE]+)', content)
                drone_viol = find_metric(r'Drone violation:\s*([0-9.+\-eE]+)', content)
                waiting_viol = find_metric(r'Waiting violation:\s*([0-9.+\-eE]+)', content)
                fitness = find_metric(r'Fitness:\s*([0-9.+\-eE]+)', content)
                routes = []
                idx = content.rfind("Route details:")
                if idx != -1:
                    for line in content[idx:].splitlines():
                        if line.startswith("Vehicle "):
                            m = re.match(r'Vehicle\s+(\d+):\s*(.+)', line)
                            if m:
                                routes.append(f"V{m.group(1)}:{m.group(2).strip()}")
                feasible = "YES" if (abs(drone_viol) < 1e-6 and abs(waiting_viol) < 1e-6) else "NO"
                return {
                    "runtime": round(runtime, 3), "makespan": round(makespan, 4),
                    "drone_violation": round(drone_viol, 4), "waiting_violation": round(waiting_viol, 4),
                    "fitness": round(fitness, 4), "feasible": feasible, "routes": " | ".join(routes)
                }
            except:
                return {"runtime": 0, "makespan": 0, "drone_violation": 0, "waiting_violation": 0,
                        "fitness": float('inf'), "feasible": "ERROR", "routes": ""}
        
        multilevel_runs = []
        for run in range(1, 6):
            result = parse_output(f"multilevel_run{run}.txt", f"multilevel_runtime{run}.txt")
            result["run"] = run
            result["algorithm"] = "Multilevel_Tabu"
            multilevel_runs.append(result)
        
        tabu_runs = []
        for run in range(1, 6):
            result = parse_output(f"tabu_run{run}.txt", f"tabu_runtime{run}.txt")
            result["run"] = run
            result["algorithm"] = "Tabu"
            tabu_runs.append(result)
        
        with open("comparison_results.json", "w", encoding="utf-8") as f:
            json.dump({"instance": instance, "multilevel_runs": multilevel_runs, "tabu_runs": tabu_runs}, f, indent=2)
        EOF
    
    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: result-${{ matrix.instance }}
        path: comparison_results.json
        retention-days: 30

  aggregate:
    name: Create Comparison Report
    needs: [run-small, run-medium, run-large]
    runs-on: ubuntu-latest
    
    steps:
    - name: Download all results
      uses: actions/download-artifact@v4
      with:
        pattern: result-*
        merge-multiple: false
    
    - name: Create detailed comparison CSV and summary
      run: |
        python3 <<'EOF'
        import json, glob, csv, os
        
        all_data = []
        
        for result_dir in glob.glob("result-*"):
            json_file = os.path.join(result_dir, "comparison_results.json")
            if os.path.exists(json_file):
                try:
                    with open(json_file) as f:
                        data = json.load(f)
                        all_data.append(data)
                except Exception as e:
                    print(f"‚ùå Failed: {json_file} - {e}")
        
        print(f"üìä Total instances: {len(all_data)}")
        
        all_data.sort(key=lambda x: tuple(int(p) for p in x["instance"].split(".")))
        
        def calculate_vehicle_distribution(num_customers):
            if 6 <= num_customers <= 12:
                pairs = 1
            elif num_customers <= 20:
                pairs = 2
            elif num_customers <= 50:
                pairs = 3
            elif num_customers <= 100:
                pairs = 4
            else:
                pairs = 0
            return pairs, pairs
        
        # ===== CREATE DETAILED CSV =====
        with open("DETAILED_COMPARISON.csv", "w", newline="", encoding="utf-8") as f:
            cols = [
                "Instance", "Size", "Num_Technician", "Num_Drone", "Replica", 
                "Algorithm", "Run", "Runtime_s", "Makespan", "Drone_Violation", 
                "Waiting_Violation", "Fitness", "Feasible", "Routes"
            ]
            
            writer = csv.DictWriter(f, fieldnames=cols)
            writer.writeheader()
            
            for data in all_data:
                parts = data["instance"].split(".")
                instance = data["instance"]
                size = int(parts[0])
                replica = int(parts[2])
                num_tech, num_drone = calculate_vehicle_distribution(size)
                
                # Write Multilevel Tabu runs
                for run_data in data.get("multilevel_runs", []):
                    writer.writerow({
                        "Instance": instance, "Size": size,
                        "Num_Technician": num_tech, "Num_Drone": num_drone,
                        "Replica": replica, "Algorithm": "Multilevel_Tabu",
                        "Run": run_data["run"], "Runtime_s": run_data["runtime"],
                        "Makespan": run_data["makespan"],
                        "Drone_Violation": run_data["drone_violation"],
                        "Waiting_Violation": run_data["waiting_violation"],
                        "Fitness": run_data["fitness"],
                        "Feasible": run_data["feasible"],
                        "Routes": run_data["routes"]
                    })
                
                # Write Tabu runs
                for run_data in data.get("tabu_runs", []):
                    writer.writerow({
                        "Instance": instance, "Size": size,
                        "Num_Technician": num_tech, "Num_Drone": num_drone,
                        "Replica": replica, "Algorithm": "Tabu",
                        "Run": run_data["run"], "Runtime_s": run_data["runtime"],
                        "Makespan": run_data["makespan"],
                        "Drone_Violation": run_data["drone_violation"],
                        "Waiting_Violation": run_data["waiting_violation"],
                        "Fitness": run_data["fitness"],
                        "Feasible": run_data["feasible"],
                        "Routes": run_data["routes"]
                    })
        
        print(f"‚úÖ DETAILED CSV created with {len(all_data) * 10} rows")
        
        # ===== CREATE COMPARISON SUMMARY =====
        with open("COMPARISON_SUMMARY.csv", "w", newline="", encoding="utf-8") as f:
            cols = [
                "Instance", "Size", "Replica",
                "ML_Avg_Fitness", "ML_Best_Fitness", "ML_Avg_Runtime",
                "Tabu_Avg_Fitness", "Tabu_Best_Fitness", "Tabu_Avg_Runtime",
                "Fitness_Gap_%", "Runtime_Gap_%", "Winner"
            ]
            
            writer = csv.DictWriter(f, fieldnames=cols)
            writer.writeheader()
            
            for data in all_data:
                parts = data["instance"].split(".")
                instance = data["instance"]
                size = int(parts[0])
                replica = int(parts[2])
                
                ml_runs = data.get("multilevel_runs", [])
                tabu_runs = data.get("tabu_runs", [])
                
                ml_fitness = [r["fitness"] for r in ml_runs if r["fitness"] != float('inf')]
                tabu_fitness = [r["fitness"] for r in tabu_runs if r["fitness"] != float('inf')]
                
                ml_runtime = [r["runtime"] for r in ml_runs if r["runtime"] > 0]
                tabu_runtime = [r["runtime"] for r in tabu_runs if r["runtime"] > 0]
                
                ml_avg_fit = sum(ml_fitness) / len(ml_fitness) if ml_fitness else float('inf')
                ml_best_fit = min(ml_fitness) if ml_fitness else float('inf')
                ml_avg_time = sum(ml_runtime) / len(ml_runtime) if ml_runtime else 0
                
                tabu_avg_fit = sum(tabu_fitness) / len(tabu_fitness) if tabu_fitness else float('inf')
                tabu_best_fit = min(tabu_fitness) if tabu_fitness else float('inf')
                tabu_avg_time = sum(tabu_runtime) / len(tabu_runtime) if tabu_runtime else 0
                
                if tabu_avg_fit > 0 and ml_avg_fit != float('inf'):
                    fitness_gap = ((ml_avg_fit - tabu_avg_fit) / tabu_avg_fit) * 100
                else:
                    fitness_gap = 0
                
                if tabu_avg_time > 0:
                    runtime_gap = ((ml_avg_time - tabu_avg_time) / tabu_avg_time) * 100
                else:
                    runtime_gap = 0
                
                if ml_best_fit < tabu_best_fit:
                    winner = "Multilevel_Tabu"
                elif tabu_best_fit < ml_best_fit:
                    winner = "Tabu"
                else:
                    winner = "Tie"
                
                writer.writerow({
                    "Instance": instance, "Size": size, "Replica": replica,
                    "ML_Avg_Fitness": round(ml_avg_fit, 4),
                    "ML_Best_Fitness": round(ml_best_fit, 4),
                    "ML_Avg_Runtime": round(ml_avg_time, 3),
                    "Tabu_Avg_Fitness": round(tabu_avg_fit, 4),
                    "Tabu_Best_Fitness": round(tabu_best_fit, 4),
                    "Tabu_Avg_Runtime": round(tabu_avg_time, 3),
                    "Fitness_Gap_%": round(fitness_gap, 2),
                    "Runtime_Gap_%": round(runtime_gap, 2),
                    "Winner": winner
                })
        
        print(f"‚úÖ COMPARISON SUMMARY created with {len(all_data)} rows")
        EOF
    
    - name: Upload comparison reports
      uses: actions/upload-artifact@v4
      with:
        name: comparison-reports
        path: |
          DETAILED_COMPARISON.csv
          COMPARISON_SUMMARY.csv
        retention-days: 90