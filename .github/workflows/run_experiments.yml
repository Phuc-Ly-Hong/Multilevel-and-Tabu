name: Compare Multilevel Tabu vs Tabu Search

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:

permissions:
  contents: read

jobs:
  compile:
    name: Compile Both Algorithms
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y g++ bc
    
    - name: Compile both executables
      run: |
        g++ -O2 -std=c++17 -o multilevel_tabu src/Multilevel_Tabu.cpp
        g++ -O2 -std=c++17 -o tabu src/Tabu.cpp
        chmod +x multilevel_tabu tabu
    
    - name: Upload executables
      uses: actions/upload-artifact@v4
      with:
        name: executables
        path: |
          multilevel_tabu
          tabu
        retention-days: 1

  run-small:
    name: Small ${{ matrix.instance }}
    needs: compile
    runs-on: ubuntu-latest
    timeout-minutes: 100
    
    strategy:
      fail-fast: false
      max-parallel: 12
      matrix:
        instance: [
          "6.5.1", "6.5.2", "6.5.3", "6.5.4",
          "6.10.1", "6.10.2", "6.10.3", "6.10.4",
          "6.20.1", "6.20.2", "6.20.3", "6.20.4",
          "10.5.1", "10.5.2", "10.5.3", "10.5.4",
          "10.10.1", "10.10.2", "10.10.3", "10.10.4",
          "10.20.1", "10.20.2", "10.20.3", "10.20.4",
          "12.5.1", "12.5.2", "12.5.3", "12.5.4",
          "12.10.1", "12.10.2", "12.10.3", "12.10.4",
          "12.20.1", "12.20.2", "12.20.3", "12.20.4",
          "20.5.1", "20.5.2", "20.5.3", "20.5.4",
          "20.10.1", "20.10.2", "20.10.3", "20.10.4",
          "20.20.1", "20.20.2", "20.20.3", "20.20.4"
        ]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Download executables
      uses: actions/download-artifact@v4
      with:
        name: executables
    
    - name: Run both algorithms 5 times each
      run: |
        chmod +x multilevel_tabu tabu
        
        for run in {1..5}; do
          START_TIME=$(date +%s.%N)
          timeout 8m ./multilevel_tabu instances/${{ matrix.instance }}.txt > multilevel_run${run}.txt 2>&1 || true
          END_TIME=$(date +%s.%N)
          echo "$(echo "$END_TIME - $START_TIME" | bc)" > multilevel_runtime${run}.txt
        done
        
        for run in {1..5}; do
          START_TIME=$(date +%s.%N)
          timeout 8m ./tabu instances/${{ matrix.instance }}.txt > tabu_run${run}.txt 2>&1 || true
          END_TIME=$(date +%s.%N)
          echo "$(echo "$END_TIME - $START_TIME" | bc)" > tabu_runtime${run}.txt
        done
    
    - name: Parse results
      run: |
        python3 <<'EOF'
        import re, json, os
        instance = "${{ matrix.instance }}"
        
        def find_metric_last(pattern, content):
            """Lấy GIÁ TRỊ CUỐI CÙNG (last match)"""
            matches = re.findall(pattern, content)
            if not matches:
                return 0.0
            try:
                return float(matches[-1])
            except:
                return 0.0
        
        def parse_output(output_file, runtime_file):
            try:
                with open(output_file, "r", encoding="utf-8", errors="ignore") as f:
                    content = f.read()
                
                runtime = 0.0
                if os.path.exists(runtime_file):
                    with open(runtime_file, "r") as f:
                        runtime = float(f.read().strip())
                
                # ✅ LẤY GIÁ TRỊ CUỐI CÙNG (final solution)
                makespan = find_metric_last(r'Makespan:\s*([0-9.+\-eE]+)', content)
                drone_viol = find_metric_last(r'Drone violation:\s*([0-9.+\-eE]+)', content)
                waiting_viol = find_metric_last(r'Waiting violation:\s*([0-9.+\-eE]+)', content)
                fitness = find_metric_last(r'Fitness:\s*([0-9.+\-eE]+)', content)
                
                feasible = "YES" if (abs(drone_viol) < 1e-6 and abs(waiting_viol) < 1e-6) else "NO"
                
                return {
                    "runtime": round(runtime, 3),
                    "makespan": round(makespan, 4),
                    "drone_violation": round(drone_viol, 4),
                    "waiting_violation": round(waiting_viol, 4),
                    "fitness": round(fitness, 4),
                    "feasible": feasible
                }
            except Exception as e:
                return {
                    "runtime": 0, "makespan": 0, "drone_violation": 0,
                    "waiting_violation": 0, "fitness": float('inf'), "feasible": "ERROR"
                }
        
        multilevel_runs = []
        for run in range(1, 6):
            result = parse_output(f"multilevel_run{run}.txt", f"multilevel_runtime{run}.txt")
            result["run"] = run
            multilevel_runs.append(result)
        
        tabu_runs = []
        for run in range(1, 6):
            result = parse_output(f"tabu_run{run}.txt", f"tabu_runtime{run}.txt")
            result["run"] = run
            tabu_runs.append(result)
        
        with open("comparison_results.json", "w") as f:
            json.dump({
                "instance": instance,
                "multilevel_runs": multilevel_runs,
                "tabu_runs": tabu_runs
            }, f, indent=2)
        EOF
    
    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: result-${{ matrix.instance }}
        path: comparison_results.json
        retention-days: 30

  run-medium:
    name: Medium ${{ matrix.instance }}
    needs: compile
    runs-on: ubuntu-latest
    timeout-minutes: 200
    
    strategy:
      fail-fast: false
      max-parallel: 8
      matrix:
        instance: [
          "50.10.1", "50.10.2", "50.10.3", "50.10.4",
          "50.20.1", "50.20.2", "50.20.3", "50.20.4",
          "50.30.1", "50.30.2", "50.30.3", "50.30.4",
          "50.40.1", "50.40.2", "50.40.3", "50.40.4"
        ]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Download executables
      uses: actions/download-artifact@v4
      with:
        name: executables
    
    - name: Run both algorithms 5 times each
      run: |
        chmod +x multilevel_tabu tabu
        
        for run in {1..5}; do
          START_TIME=$(date +%s.%N)
          timeout 18m ./multilevel_tabu instances/${{ matrix.instance }}.txt > multilevel_run${run}.txt 2>&1 || true
          END_TIME=$(date +%s.%N)
          echo "$(echo "$END_TIME - $START_TIME" | bc)" > multilevel_runtime${run}.txt
        done
        
        for run in {1..5}; do
          START_TIME=$(date +%s.%N)
          timeout 18m ./tabu instances/${{ matrix.instance }}.txt > tabu_run${run}.txt 2>&1 || true
          END_TIME=$(date +%s.%N)
          echo "$(echo "$END_TIME - $START_TIME" | bc)" > tabu_runtime${run}.txt
        done
    
    - name: Parse results
      run: |
        python3 <<'EOF'
        import re, json, os
        instance = "${{ matrix.instance }}"
        
        def find_metric_last(pattern, content):
            matches = re.findall(pattern, content)
            return float(matches[-1]) if matches else 0.0
        
        def parse_output(output_file, runtime_file):
            try:
                with open(output_file, "r", encoding="utf-8", errors="ignore") as f:
                    content = f.read()
                runtime = 0.0
                if os.path.exists(runtime_file):
                    with open(runtime_file, "r") as f:
                        runtime = float(f.read().strip())
                makespan = find_metric_last(r'Makespan:\s*([0-9.+\-eE]+)', content)
                drone_viol = find_metric_last(r'Drone violation:\s*([0-9.+\-eE]+)', content)
                waiting_viol = find_metric_last(r'Waiting violation:\s*([0-9.+\-eE]+)', content)
                fitness = find_metric_last(r'Fitness:\s*([0-9.+\-eE]+)', content)
                feasible = "YES" if (abs(drone_viol) < 1e-6 and abs(waiting_viol) < 1e-6) else "NO"
                return {"runtime": round(runtime, 3), "makespan": round(makespan, 4),
                        "drone_violation": round(drone_viol, 4), "waiting_violation": round(waiting_viol, 4),
                        "fitness": round(fitness, 4), "feasible": feasible}
            except:
                return {"runtime": 0, "makespan": 0, "drone_violation": 0, "waiting_violation": 0,
                        "fitness": float('inf'), "feasible": "ERROR"}
        
        multilevel_runs = [parse_output(f"multilevel_run{i}.txt", f"multilevel_runtime{i}.txt") | {"run": i} 
                          for i in range(1, 6)]
        tabu_runs = [parse_output(f"tabu_run{i}.txt", f"tabu_runtime{i}.txt") | {"run": i} 
                    for i in range(1, 6)]
        
        with open("comparison_results.json", "w") as f:
            json.dump({"instance": instance, "multilevel_runs": multilevel_runs, "tabu_runs": tabu_runs}, f, indent=2)
        EOF
    
    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: result-${{ matrix.instance }}
        path: comparison_results.json
        retention-days: 30

  run-large:
    name: Large ${{ matrix.instance }}
    needs: compile
    runs-on: ubuntu-latest
    timeout-minutes: 400
    
    strategy:
      fail-fast: false
      max-parallel: 6
      matrix:
        instance: [
          "100.10.1", "100.10.2", "100.10.3", "100.10.4",
          "100.20.1", "100.20.2", "100.20.3", "100.20.4",
          "100.30.1", "100.30.2", "100.30.3", "100.30.4",
          "100.40.1", "100.40.2", "100.40.3", "100.40.4"
        ]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Download executables
      uses: actions/download-artifact@v4
      with:
        name: executables
    
    - name: Run both algorithms 5 times each
      run: |
        chmod +x multilevel_tabu tabu
        
        for run in {1..5}; do
          START_TIME=$(date +%s.%N)
          timeout 35m ./multilevel_tabu instances/${{ matrix.instance }}.txt > multilevel_run${run}.txt 2>&1 || true
          END_TIME=$(date +%s.%N)
          echo "$(echo "$END_TIME - $START_TIME" | bc)" > multilevel_runtime${run}.txt
        done
        
        for run in {1..5}; do
          START_TIME=$(date +%s.%N)
          timeout 35m ./tabu instances/${{ matrix.instance }}.txt > tabu_run${run}.txt 2>&1 || true
          END_TIME=$(date +%s.%N)
          echo "$(echo "$END_TIME - $START_TIME" | bc)" > tabu_runtime${run}.txt
        done
    
    - name: Parse results
      run: |
        python3 <<'EOF'
        import re, json, os
        instance = "${{ matrix.instance }}"
        
        def find_metric_last(pattern, content):
            matches = re.findall(pattern, content)
            return float(matches[-1]) if matches else 0.0
        
        def parse_output(output_file, runtime_file):
            try:
                with open(output_file, "r", encoding="utf-8", errors="ignore") as f:
                    content = f.read()
                runtime = 0.0
                if os.path.exists(runtime_file):
                    with open(runtime_file, "r") as f:
                        runtime = float(f.read().strip())
                makespan = find_metric_last(r'Makespan:\s*([0-9.+\-eE]+)', content)
                drone_viol = find_metric_last(r'Drone violation:\s*([0-9.+\-eE]+)', content)
                waiting_viol = find_metric_last(r'Waiting violation:\s*([0-9.+\-eE]+)', content)
                fitness = find_metric_last(r'Fitness:\s*([0-9.+\-eE]+)', content)
                feasible = "YES" if (abs(drone_viol) < 1e-6 and abs(waiting_viol) < 1e-6) else "NO"
                return {"runtime": round(runtime, 3), "makespan": round(makespan, 4),
                        "drone_violation": round(drone_viol, 4), "waiting_violation": round(waiting_viol, 4),
                        "fitness": round(fitness, 4), "feasible": feasible}
            except:
                return {"runtime": 0, "makespan": 0, "drone_violation": 0, "waiting_violation": 0,
                        "fitness": float('inf'), "feasible": "ERROR"}
        
        multilevel_runs = [parse_output(f"multilevel_run{i}.txt", f"multilevel_runtime{i}.txt") | {"run": i} 
                          for i in range(1, 6)]
        tabu_runs = [parse_output(f"tabu_run{i}.txt", f"tabu_runtime{i}.txt") | {"run": i} 
                    for i in range(1, 6)]
        
        with open("comparison_results.json", "w") as f:
            json.dump({"instance": instance, "multilevel_runs": multilevel_runs, "tabu_runs": tabu_runs}, f, indent=2)
        EOF
    
    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: result-${{ matrix.instance }}
        path: comparison_results.json
        retention-days: 30

  aggregate:
    name: Create Comparison Summary
    needs: [run-small, run-medium, run-large]
    runs-on: ubuntu-latest
    
    steps:
    - name: Download all results
      uses: actions/download-artifact@v4
      with:
        pattern: result-*
        merge-multiple: false
    
    - name: Create summary CSV
      run: |
        python3 <<'EOF'
        import json, glob, csv, os, statistics
        
        all_data = []
        for result_dir in glob.glob("result-*"):
            json_file = os.path.join(result_dir, "comparison_results.json")
            if os.path.exists(json_file):
                with open(json_file) as f:
                    all_data.append(json.load(f))
        
        all_data.sort(key=lambda x: tuple(map(int, x["instance"].split("."))))
        
        # ===== SUMMARY BY INSTANCE =====
        with open("COMPARISON_SUMMARY.csv", "w", newline="") as f:
            cols = ["Instance", "Size", "Replica",
                    "ML_Avg_Fitness", "ML_Best_Fitness", "ML_Avg_Time",
                    "Tabu_Avg_Fitness", "Tabu_Best_Fitness", "Tabu_Avg_Time",
                    "Fitness_Gap_%", "Time_Speedup_%", "Winner"]
            
            writer = csv.DictWriter(f, fieldnames=cols)
            writer.writeheader()
            
            for data in all_data:
                parts = data["instance"].split(".")
                instance, size, replica = data["instance"], int(parts[0]), int(parts[2])
                
                ml_fit = [r["fitness"] for r in data["multilevel_runs"] if r["fitness"] != float('inf')]
                tabu_fit = [r["fitness"] for r in data["tabu_runs"] if r["fitness"] != float('inf')]
                ml_time = [r["runtime"] for r in data["multilevel_runs"] if r["runtime"] > 0]
                tabu_time = [r["runtime"] for r in data["tabu_runs"] if r["runtime"] > 0]
                
                ml_avg = statistics.mean(ml_fit) if ml_fit else float('inf')
                ml_best = min(ml_fit) if ml_fit else float('inf')
                ml_avg_t = statistics.mean(ml_time) if ml_time else 0
                
                tabu_avg = statistics.mean(tabu_fit) if tabu_fit else float('inf')
                tabu_best = min(tabu_fit) if tabu_fit else float('inf')
                tabu_avg_t = statistics.mean(tabu_time) if tabu_time else 0
                
                fit_gap = ((ml_avg - tabu_avg) / tabu_avg * 100) if tabu_avg > 0 else 0
                time_speedup = ((tabu_avg_t - ml_avg_t) / tabu_avg_t * 100) if tabu_avg_t > 0 else 0
                
                winner = "ML" if ml_best < tabu_best else ("Tabu" if tabu_best < ml_best else "Tie")
                
                writer.writerow({
                    "Instance": instance, "Size": size, "Replica": replica,
                    "ML_Avg_Fitness": f"{ml_avg:.4f}", "ML_Best_Fitness": f"{ml_best:.4f}",
                    "ML_Avg_Time": f"{ml_avg_t:.3f}",
                    "Tabu_Avg_Fitness": f"{tabu_avg:.4f}", "Tabu_Best_Fitness": f"{tabu_best:.4f}",
                    "Tabu_Avg_Time": f"{tabu_avg_t:.3f}",
                    "Fitness_Gap_%": f"{fit_gap:.2f}", "Time_Speedup_%": f"{time_speedup:.2f}",
                    "Winner": winner
                })
        
        # ===== OVERALL STATISTICS =====
        with open("OVERALL_STATS.csv", "w", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(["Metric", "Multilevel_Tabu", "Tabu", "Gap_%"])
            
            all_ml_fit = [r["fitness"] for d in all_data for r in d["multilevel_runs"] if r["fitness"] != float('inf')]
            all_tabu_fit = [r["fitness"] for d in all_data for r in d["tabu_runs"] if r["fitness"] != float('inf')]
            all_ml_time = [r["runtime"] for d in all_data for r in d["multilevel_runs"] if r["runtime"] > 0]
            all_tabu_time = [r["runtime"] for d in all_data for r in d["tabu_runs"] if r["runtime"] > 0]
            
            ml_avg_fit = statistics.mean(all_ml_fit)
            tabu_avg_fit = statistics.mean(all_tabu_fit)
            ml_avg_time = statistics.mean(all_ml_time)
            tabu_avg_time = statistics.mean(all_tabu_time)
            
            fit_gap = (ml_avg_fit - tabu_avg_fit) / tabu_avg_fit * 100
            time_gap = (ml_avg_time - tabu_avg_time) / tabu_avg_time * 100
            
            writer.writerow(["Avg Fitness", f"{ml_avg_fit:.4f}", f"{tabu_avg_fit:.4f}", f"{fit_gap:.2f}"])
            writer.writerow(["Avg Runtime", f"{ml_avg_time:.3f}", f"{tabu_avg_time:.3f}", f"{time_gap:.2f}"])
            
            ml_wins = sum(1 for d in all_data 
                         if min(r["fitness"] for r in d["multilevel_runs"]) < 
                            min(r["fitness"] for r in d["tabu_runs"]))
            tabu_wins = len(all_data) - ml_wins
            
            writer.writerow(["Wins", ml_wins, tabu_wins, f"{ml_wins/len(all_data)*100:.1f}"])
        
        print(f"✅ Summary created: {len(all_data)} instances")
        EOF
    
    - name: Upload reports
      uses: actions/upload-artifact@v4
      with:
        name: comparison-reports
        path: |
          COMPARISON_SUMMARY.csv
          OVERALL_STATS.csv
        retention-days: 90